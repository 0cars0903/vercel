import ollama
import os
import json
import re
import time
from PIL import Image, ImageEnhance
import io
import base64
import requests
import qrcode
from datetime import datetime
import kss  # í•œêµ­ì–´ ë¬¸ì¥ ë¶„ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import zipfile # ì••ì¶• íŒŒì¼ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# --- .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---
import dotenv
dotenv.load_dotenv()

# NAVER CLOVA OCR í™˜ê²½ ë³€ìˆ˜
NAVER_OCR_SECRET_KEY = os.environ.get('NAVER_OCR_SECRET_KEY')
NAVER_OCR_INVOKE_URL = os.environ.get('NAVER_OCR_INVOKE_URL')

# --------------------------------------------------------------------------
# ğŸ¤– Agent 1: OCR Agent (Naver Cloud OCR ì‚¬ìš©) - ê¸°ì¡´ê³¼ ë™ì¼
# --------------------------------------------------------------------------
def ocr_agent(image_path: str) -> list[dict]:
    print(f"\n[ OCR Agent using Naver Cloud OCR ] '{os.path.basename(image_path)}' ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")
    
    # 1. ìš”ì²­ì— í•„ìš”í•œ ì •ë³´ êµ¬ì„±
    request_body = {
        'version': 'V2',
        'requestId': 'NCP-OCR-ID-' + str(int(time.time() * 1000)), 
        'timestamp': int(time.time() * 1000),
        'lang': 'ko', 
        'images': [
            {
                'format': os.path.splitext(image_path)[1][1:].upper(),
                'name': os.path.basename(image_path),
            }
        ]
    }
    
    headers = { 'X-OCR-Secret': NAVER_OCR_SECRET_KEY }

    try:
        with open(image_path, 'rb') as img_file:
            files = {
                'file': (os.path.basename(image_path), img_file, 'image/' + os.path.splitext(image_path)[1][1:].lower()),
                'message': (None, json.dumps(request_body).encode('UTF-8'), 'application/json')
            }
            response = requests.post(NAVER_OCR_INVOKE_URL, headers=headers, files=files)
            response.raise_for_status()

        result_json = response.json()
        
        full_text = ""
        for image_result in result_json.get('images', []):
            for field in image_result.get('fields', []):
                full_text += field.get('inferText', '') + " "

        processed_text = full_text.strip().replace('\n', ' ')
        sentences = kss.split_sentences(processed_text)
        
        ocr_results = [{'id': idx + 1, 'text': sentence.strip()} for idx, sentence in enumerate(sentences) if sentence.strip()]
        
        print(f"OCR ì™„ë£Œ: ì´ {len(ocr_results)}ê°œì˜ ë¬¸ì¥ ì¶”ì¶œ")
        return ocr_results

    except requests.exceptions.RequestException as e:
        print(f"[Naver Cloud OCR ì˜¤ë¥˜] ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” API ìš”ì²­ ì˜¤ë¥˜: {e}")
        if e.response is not None:
             print(f"ì‘ë‹µ ì½”ë“œ: {e.response.status_code}, ì‘ë‹µ ë‚´ìš©: {e.response.text}")
        return []
    except Exception as e:
        print(f"[Naver Cloud OCR ì˜¤ë¥˜] ì˜ˆì¸¡í•˜ì§€ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --------------------------------------------------------------------------
# ğŸ§© ëª¨ë“ˆ 2: LLM ì •ë³´ ì¶”ì¶œê¸° (ë‹¨ì¼ ì–¸ì–´ìš©)
# --------------------------------------------------------------------------
def extract_structured_info_with_retry(raw_text: str, max_retries: int = 3, model_name: str = 'mistral:latest') -> dict:
    print(f"\n[ ì •ë³´ êµ¬ì¡°í™” ì‹œì‘ (ë‹¨ì¼ ì–¸ì–´) ]")
    # ... (ê¸°ì¡´ ì½”ë“œì™€ ëŒ€ë¶€ë¶„ ë™ì¼, í”„ë¡¬í”„íŠ¸ë§Œ ì•½ê°„ ìˆ˜ì •)
    prompt = f"""
    You are an expert business card information extractor.
    From the provided text, extract the required information into a valid JSON format.
    - For missing information, use an empty string "".
    - Return ONLY valid JSON.
    
    Required JSON structure:
    {{
        "name": "", "title": "", "company": "", "phone": "", "email": "", "address": ""
    }}

    --- Text to Analyze ---
    {raw_text}
    """
    # ... (ì´í•˜ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    for attempt in range(max_retries):
        try:
            # ... (Ollama í˜¸ì¶œ ë° íŒŒì‹± ë¡œì§)
            response = ollama.chat(model=model_name, messages=[{'role': 'user', 'content': prompt}], format='json')
            parsed_json = json.loads(response['message']['content'])
            validated_data = validate_and_clean_contact_info(parsed_json)
            print("  âœ… ì •ë³´ êµ¬ì¡°í™” ì„±ê³µ")
            return validated_data
        except Exception as e:
            print(f"  ğŸš¨ ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
    return get_default_contact_info()

# --------------------------------------------------------------------------
# âœ¨ Agent 2: ì–‘ë©´ ëª…í•¨ ë¶„ì„ ì—ì´ì „íŠ¸ (ì‹ ê·œ ì¶”ê°€) âœ¨
# --------------------------------------------------------------------------
def two_sided_extract_agent(front_text: str, back_text: str, max_retries: int = 3, model_name: str = 'mistral:latest') -> dict:
    """
    ì–‘ë©´ ëª…í•¨ì˜ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ í•œê¸€/ì˜ë¬¸ ì •ë³´ë¥¼ ë¶„ë¦¬í•˜ì—¬ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.
    """
    print(f"\n[ ì •ë³´ êµ¬ì¡°í™” ì‹œì‘ (ì–‘ë©´ ë¶„ì„) ]")
    
    combined_text = f"--- Front Side (Korean) ---\n{front_text}\n\n--- Back Side (English) ---\n{back_text}"
    
    prompt = f"""
    You are an expert business card extractor for two-sided (Korean/English) cards.
    The provided text contains text from both sides. Extract the information into the following JSON structure.
    - Fill `_ko` fields from Korean text and `_en` fields from English text.
    - For missing information, use an empty string "".
    - `phone` and `email` are usually the same on both sides.
    - Return ONLY valid JSON.

    Required JSON structure:
    {{
        "name_ko": "", "name_en": "",
        "title_ko": "", "title_en": "",
        "company_ko": "", "company_en": "",
        "phone": "", "email": "",
        "address_ko": "", "address_en": ""
    }}

    --- Combined Text to Analyze ---
    {combined_text}
    """

    for attempt in range(max_retries):
        try:
            response = ollama.chat(
                model=model_name,
                messages=[{'role': 'user', 'content': prompt}],
                format='json'
            )
            parsed_json = json.loads(response['message']['content'])
            # ì–‘ë©´ ë°ì´í„°ì— ëŒ€í•œ ê²€ì¦ ë° ì •ì œ í•¨ìˆ˜ í˜¸ì¶œ (ë³„ë„ êµ¬í˜„)
            validated_data = validate_and_clean_bilingual_info(parsed_json)
            print("  âœ… ì–‘ë©´ ì •ë³´ êµ¬ì¡°í™” ì„±ê³µ")
            return validated_data
        except Exception as e:
            print(f"  ğŸš¨ ì–‘ë©´ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
    
    return get_default_bilingual_contact_info()

# --------------------------------------------------------------------------
# ğŸ§© ëª¨ë“ˆ 3: ë°ì´í„° ê²€ì¦, ì •ì œ ë° í¬ë§·íŒ… (ê¸°ëŠ¥ í™•ì¥)
# --------------------------------------------------------------------------
def get_default_contact_info():
    return {"name": "", "title": "", "company": "", "phone": "", "email": "", "address": ""}

def get_default_bilingual_contact_info():
    return {
        "name_ko": "", "name_en": "", "title_ko": "", "title_en": "",
        "company_ko": "", "company_en": "", "phone": "", "email": "",
        "address_ko": "", "address_en": ""
    }

def validate_and_clean_contact_info(data: dict) -> dict:
    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    cleaned_data = get_default_contact_info()
    for key in cleaned_data.keys():
        if key in data and isinstance(data[key], str):
            cleaned_data[key] = data[key].strip()
    if cleaned_data.get('phone'):
        cleaned_data['phone'] = normalize_phone_number(cleaned_data['phone'])
    return cleaned_data

def validate_and_clean_bilingual_info(data: dict) -> dict:
    cleaned_data = get_default_bilingual_contact_info()
    for key in cleaned_data.keys():
        if key in data and isinstance(data[key], str):
            cleaned_data[key] = data[key].strip()
    if cleaned_data.get('phone'):
        cleaned_data['phone'] = normalize_phone_number(cleaned_data['phone'])
    return cleaned_data

def normalize_phone_number(phone: str) -> str:
    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    digits = re.sub(r'[^\d]', '', phone)
    if len(digits) == 10: return f"{digits[:2]}-{digits[2:6]}-{digits[6:]}"
    if len(digits) == 11: return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
    return phone

def format_contact_summary(data: dict) -> str:
    if 'name_ko' in data: # ì–‘ë©´ ë°ì´í„° í˜•ì‹
        name = data.get('name_ko') or data.get('name_en')
        company = data.get('company_ko') or data.get('company_en')
        return f"{name} ({company})" if name else "ì •ë³´ ì—†ìŒ"
    else: # ë‹¨ë©´ ë°ì´í„° í˜•ì‹
        name = data.get('name')
        company = data.get('company')
        return f"{name} ({company})" if name else "ì •ë³´ ì—†ìŒ"

# --------------------------------------------------------------------------
# ğŸ§© ëª¨ë“ˆ 4: VCF ë° QR ì½”ë“œ ìƒì„± (ê¸°ëŠ¥ í™•ì¥)
# --------------------------------------------------------------------------
def generate_vcf_content(data: dict) -> str:
    """VCF í˜•ì‹ì˜ ì—°ë½ì²˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ì–‘ë©´ ì§€ì›)."""
    vcf_lines = ["BEGIN:VCARD", "VERSION:3.0"]
    
    if 'name_ko' in data: # ì–‘ë©´ ë°ì´í„° ì²˜ë¦¬
        name_ko, name_en = data.get('name_ko'), data.get('name_en')
        title_ko, title_en = data.get('title_ko'), data.get('title_en')
        
        if name_ko or name_en:
            # VCF í‘œì¤€ì— ë”°ë¼ ì„±ê³¼ ì´ë¦„ì„ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ í†µí•©
            vcf_lines.append(f"N;CHARSET=UTF-8:{name_ko};{name_en};;;")
            vcf_lines.append(f"FN;CHARSET=UTF-8:{name_ko}{' ' if name_ko and name_en else ''}{name_en}")
        
        if title_ko or title_en:
            vcf_lines.append(f"TITLE;CHARSET=UTF-8:{title_ko}{' / ' if title_ko and title_en else ''}{title_en}")
        
        vcf_lines.append(f"ORG;CHARSET=UTF-8:{data.get('company_ko', '')}")
    
    else: # ë‹¨ë©´ ë°ì´í„° ì²˜ë¦¬
        if data.get('name'):
            vcf_lines.append(f"N:{data['name']};;;;")
            vcf_lines.append(f"FN:{data['name']}")
        if data.get('title'):
            vcf_lines.append(f"TITLE:{data['title']}")
        if data.get('company'):
            vcf_lines.append(f"ORG:{data['company']}")
            
    # ê³µí†µ í•„ë“œ
    if data.get('phone'):
        vcf_lines.append(f"TEL;TYPE=WORK,VOICE:{data['phone']}")
    if data.get('email'):
        vcf_lines.append(f"EMAIL;TYPE=WORK:{data['email']}")
    if data.get('address_ko') or data.get('address'):
        address = data.get('address_ko', '') or data.get('address', '')
        vcf_lines.append(f"ADR;TYPE=WORK;CHARSET=UTF-8:;;{address};;;;")

    vcf_lines.append(f"REV:{datetime.now().strftime('%Y%m%dT%H%M%SZ')}")
    vcf_lines.append("END:VCARD")
    return '\n'.join(vcf_lines)

# --------------------------------------------------------------------------
# ğŸš€ ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ê¸°ì¡´ ë‹¨ì¼ ì²˜ë¦¬ìš©)
# --------------------------------------------------------------------------
def run_pipeline(image_path: str, output_dir: str = "output"):
    ocr_results_list = ocr_agent(image_path)
    if not ocr_results_list:
        print("ì´ë¯¸ì§€ ì¸ì‹ ì‹¤íŒ¨")
        return
    full_ocr_text = ' '.join([item['text'] for item in ocr_results_list])
    structured_data = extract_structured_info_with_retry(full_ocr_text)
    
    # ... (ì‚¬ìš©ì í™•ì¸ ë° ìˆ˜ì • ë£¨í”„ëŠ” ë°°ì¹˜ ì²˜ë¦¬ì—ì„œ ê´€ë¦¬)
    
    final_data = structured_data # ì—¬ê¸°ì„œëŠ” ë°”ë¡œ ìµœì¢… ë°ì´í„°ë¡œ ê°„ì£¼
    
    # VCF ë° QR ì½”ë“œ ìƒì„±
    # ...
    print("\nğŸ‰ ë‹¨ì¼ ëª…í•¨ ì²˜ë¦¬ ì™„ë£Œ!")

# --------------------------------------------------------------------------
# âœ¨ ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬ ë° ê´€ë¦¬ íŒŒì´í”„ë¼ì¸ (ì‹ ê·œ ì¶”ê°€) âœ¨
# --------------------------------------------------------------------------
def run_batch_pipeline(image_paths: list[str], output_dir: str = "output"):
    """ì—¬ëŸ¬ ëª…í•¨ ì´ë¯¸ì§€ë¥¼ ì¼ê´„ ì²˜ë¦¬í•˜ê³ , ê²°ê³¼ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤."""
    print("ğŸš€ ë‹¤ì¤‘ ëª…í•¨ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    os.makedirs(output_dir, exist_ok=True)
    
    processed_data = []
    # 1. ëª¨ë“  íŒŒì¼ ìë™ ì²˜ë¦¬
    for img_path in image_paths:
        print("-" * 50)
        ocr_results_list = ocr_agent(img_path)
        if not ocr_results_list:
            continue
        full_ocr_text = ' '.join([item['text'] for item in ocr_results_list])
        structured_data = extract_structured_info_with_retry(full_ocr_text)
        processed_data.append({'source': os.path.basename(img_path), 'data': structured_data})

    # 2. ê²°ê³¼ ëª©ë¡ ë³´ì—¬ì£¼ê¸° ë° ê´€ë¦¬ ë£¨í”„
    filtered_indices = list(range(len(processed_data))) # ì´ˆê¸°ì—ëŠ” ì „ì²´ ëª©ë¡
    
    while True:
        print("\n" + "="*60)
        print("ğŸ“‹ ì²˜ë¦¬ ê²°ê³¼ ëª©ë¡ (ìš°ì¸¡ íŒ¨ë„)")
        print("-" * 60)
        
        if not filtered_indices:
            print("  í‘œì‹œí•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ê²°ê³¼ ì—†ìŒ)")
        else:
            for i, original_idx in enumerate(filtered_indices):
                item = processed_data[original_idx]
                summary = format_contact_summary(item['data'])
                print(f"  {i+1:2d}. [{item['source']}] -> {summary}")

        print("-" * 60)
        print("  [F]ilter: ê²°ê³¼ í•„í„°ë§ | [E]dit: í•­ëª© ìˆ˜ì • | [R]eset: í•„í„° ì´ˆê¸°í™”")
        print("  [D]ownload: VCF ë‹¤ìš´ë¡œë“œ | [Q]uit: ì¢…ë£Œ")
        choice = input("ì„ íƒí•˜ì„¸ìš”: ").strip().upper()

        if choice == 'F':
            keyword = input("  ğŸ” ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì´ë¦„, íšŒì‚¬ ë“±): ").strip()
            if keyword:
                filtered_indices = [
                    i for i, item in enumerate(processed_data)
                    if keyword.lower() in str(item['data'].values()).lower()
                ]
            else:
                 print("  âš ï¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        elif choice == 'R':
            filtered_indices = list(range(len(processed_data)))
            print("  ğŸ”„ í•„í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

        elif choice == 'E':
            if not filtered_indices:
                 print("  âš ï¸ ìˆ˜ì •í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                 continue
            try:
                target_num = int(input(f"  ìˆ˜ì •í•  í•­ëª©ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{len(filtered_indices)}): ").strip())
                if 1 <= target_num <= len(filtered_indices):
                    original_idx = filtered_indices[target_num - 1]
                    # ìƒì„¸ ìˆ˜ì • ë¡œì§ (ê¸°ì¡´ edit_all_fields ì¬í™œìš©)
                    # ì‹¤ì œ ì›¹ì´ë¼ë©´ ì—¬ê¸°ì„œ íŒì—…/í˜ì´ì§€ ì´ë™
                    print(f"\nğŸ“ '{processed_data[original_idx]['source']}' ì •ë³´ ìˆ˜ì •")
                    processed_data[original_idx]['data'] = edit_all_fields(processed_data[original_idx]['data'])
                else:
                    print("  âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
            except ValueError:
                print("  âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        elif choice == 'D':
            if not filtered_indices:
                 print("  âš ï¸ ë‹¤ìš´ë¡œë“œí•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                 continue
            
            # í˜„ì¬ í•„í„°ë§ëœ í•­ëª©ë“¤ë§Œ ë‹¤ìš´ë¡œë“œ ëŒ€ìƒìœ¼ë¡œ ì„ ì •
            items_to_download = [processed_data[i] for i in filtered_indices]
            
            # 3. VCF íŒŒì¼ ìƒì„± ë° ì••ì¶•
            vcf_files = []
            for item in items_to_download:
                vcf_content = generate_vcf_content(item['data'])
                name = item['data'].get('name_ko') or item['data'].get('name', 'contact')
                safe_name = re.sub(r'[^\w\s-]', '', name).strip()
                vcf_filename = os.path.join(output_dir, f"{safe_name}.vcf")
                with open(vcf_filename, 'w', encoding='utf-8') as f:
                    f.write(vcf_content)
                vcf_files.append(vcf_filename)
                print(f"  âœ… VCF íŒŒì¼ ìƒì„±: {vcf_filename}")

            if len(vcf_files) >= 5:
                zip_filename = os.path.join(output_dir, f"contacts_{datetime.now().strftime('%Y%m%d')}.zip")
                print(f"\n  ğŸ—œï¸ 5ê°œ ì´ìƒì´ë¯€ë¡œ ì••ì¶• íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤: {zip_filename}")
                with zipfile.ZipFile(zip_filename, 'w') as zf:
                    for file in vcf_files:
                        zf.write(file, os.path.basename(file))
                print("  âœ… ì••ì¶• ì™„ë£Œ!")
            
            print("\nğŸ‰ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            break

        elif choice == 'Q':
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
# (edit_all_fields, edit_specific_field ë“± ì‚¬ìš©ì ìˆ˜ì • í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
def edit_all_fields(data: dict) -> dict:
    """ëª¨ë“  í•„ë“œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    # ... ê¸°ì¡´ ì½”ë“œ ...
    print("\nğŸ“ ì „ì²´ ì •ë³´ë¥¼ ë‹¤ì‹œ ì…ë ¥í•©ë‹ˆë‹¤. (Enterë§Œ ëˆ„ë¥´ë©´ ê¸°ì¡´ ê°’ ìœ ì§€)")
    
    labels = {}
    if 'name_ko' in data: # ì–‘ë©´ ë°ì´í„°ìš© ë ˆì´ë¸”
        labels = {
            'name_ko': 'ì´ë¦„(í•œê¸€)', 'name_en': 'ì´ë¦„(ì˜ë¬¸)',
            'title_ko': 'ì§ì±…(í•œê¸€)', 'title_en': 'ì§ì±…(ì˜ë¬¸)',
            'company_ko': 'íšŒì‚¬(í•œê¸€)', 'company_en': 'íšŒì‚¬(ì˜ë¬¸)',
            'phone': 'ì „í™”ë²ˆí˜¸', 'email': 'ì´ë©”ì¼',
            'address_ko': 'ì£¼ì†Œ(í•œê¸€)', 'address_en': 'ì£¼ì†Œ(ì˜ë¬¸)'
        }
    else: # ë‹¨ë©´ ë°ì´í„°ìš© ë ˆì´ë¸”
        labels = {'name': 'ì´ë¦„', 'title': 'ì§ì±…', 'company': 'íšŒì‚¬', 'phone': 'ì „í™”ë²ˆí˜¸', 'email': 'ì´ë©”ì¼', 'address': 'ì£¼ì†Œ'}

    for key, label in labels.items():
        current_value = data.get(key, '')
        prompt = f"  {label} (í˜„ì¬: {current_value or 'ì—†ìŒ'}): "
        new_value = input(prompt).strip()
        if new_value:
            data[key] = new_value
    
    print("âœ… ì „ì²´ ì •ë³´ ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return data

# --------------------------------------------------------------------------
# ì‹¤í–‰ ë¶€ë¶„
# --------------------------------------------------------------------------
if __name__ == "__main__":
    # --- ì‹œë‚˜ë¦¬ì˜¤ 1: ì—¬ëŸ¬ ê°œì˜ ë‹¨ë©´ ëª…í•¨ ì¼ê´„ ì²˜ë¦¬ ---
    print("="*60)
    print("ğŸ”¥ ì‹œë‚˜ë¦¬ì˜¤ 1: ì—¬ëŸ¬ ê°œì˜ ë‹¨ë©´ ëª…í•¨ ì¼ê´„ ì²˜ë¦¬")
    print("="*60)
    
    # ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ (sample_data í´ë”ì— ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¤€ë¹„)
    batch_image_paths = [
        "sample_data/real.jpeg",
        "sample_data/card2.png", # ê°€ìƒì˜ íŒŒì¼ ê²½ë¡œ
        "sample_data/card3.png"  # ê°€ìƒì˜ íŒŒì¼ ê²½ë¡œ
    ]
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ ëŒ€ìƒìœ¼ë¡œ ì²˜ë¦¬
    existing_files = [p for p in batch_image_paths if os.path.exists(p)]
    if not existing_files:
        print("âš ï¸ ì²˜ë¦¬í•  ìƒ˜í”Œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. 'sample_data' í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        run_batch_pipeline(existing_files)

    # --- ì‹œë‚˜ë¦¬ì˜¤ 2: ì–‘ë©´ ëª…í•¨ ì²˜ë¦¬ ---
    print("\n\n" + "="*60)
    print("ğŸ”¥ ì‹œë‚˜ë¦¬ì˜¤ 2: ì–‘ë©´ ëª…í•¨ ì²˜ë¦¬ (ì•/ë’·ë©´)")
    print("="*60)
    
    front_image_path = "sample_data/real_ko.jpeg" # í•œê¸€ ëª…í•¨ ê²½ë¡œ
    back_image_path = "sample_data/real_en.jpeg" # ì˜ë¬¸ ëª…í•¨ ê²½ë¡œ (ê°€ìƒ)

    if os.path.exists(front_image_path) and os.path.exists(back_image_path):
        # 1. ê° ë©´ OCR
        front_ocr_list = ocr_agent(front_image_path)
        back_ocr_list = ocr_agent(back_image_path)

        if front_ocr_list and back_ocr_list:
            front_text = ' '.join([item['text'] for item in front_ocr_list])
            back_text = ' '.join([item['text'] for item in back_ocr_list])
            
            # 2. ì–‘ë©´ ë¶„ì„ ì—ì´ì „íŠ¸ í˜¸ì¶œ
            bilingual_data = two_sided_extract_agent(front_text, back_text)
            
            # 3. ê²°ê³¼ í™•ì¸ ë° VCF ìƒì„±
            print("\n[ ìµœì¢… ì–‘ë©´ ë¶„ì„ ê²°ê³¼ ]")
            print(json.dumps(bilingual_data, indent=2, ensure_ascii=False))

            vcf_content = generate_vcf_content(bilingual_data)
            output_path = f"output/{bilingual_data.get('name_en', 'bilingual_contact')}.vcf"
            os.makedirs('output', exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(vcf_content)
            print(f"\nâœ… ì–‘ë©´ ëª…í•¨ VCF íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}")

    else:
        print("âš ï¸ ì–‘ë©´ ëª…í•¨ ìƒ˜í”Œ ì´ë¯¸ì§€ê°€ ëª¨ë‘ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

